"""
Advanced Anomaly Detection Visualizer for Real-Time Anomaly Detection Project
Creates comprehensive anomaly detection graphs and visualizations
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.figure_factory as ff
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# Add project path
sys.path.insert(0, os.path.dirname(__file__))

class AnomalyDetectionVisualizer:
    """
    Advanced anomaly detection visualizer for the real-time anomaly detection project
    Features:
    - Real-time anomaly detection graphs
    - Anomaly clustering and pattern analysis
    - Performance metrics visualization
    - Interactive anomaly exploration
    """
    
    def __init__(self, output_dir: str = "anomaly_visualizations"):
        """
        Initialize anomaly detection visualizer
        
        Args:
            output_dir: Directory to save visualizations
        """
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Set up plotting style
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        print(f"üîç Anomaly Detection Visualizer initialized")
        print(f"üìÅ Output directory: {self.output_dir}")
    
    def create_comprehensive_anomaly_analysis(self, ticker: str, df: pd.DataFrame, 
                                            anomaly_scores: List[float],
                                            anomaly_flags: List[bool],
                                            anomaly_types: List[str] = None) -> str:
        """
        Create comprehensive anomaly detection analysis
        
        Args:
            ticker: Stock ticker symbol
            df: Historical data
            anomaly_scores: Anomaly scores (0-1)
            anomaly_flags: Binary anomaly flags
            anomaly_types: Types of anomalies detected
            
        Returns:
            Path to saved visualization
        """
        try:
            fig = make_subplots(
                rows=4, cols=2,
                subplot_titles=(
                    'Price with Anomaly Detection',
                    'Anomaly Score Timeline',
                    'Anomaly Distribution',
                    'Anomaly Clustering',
                    'Volatility vs Anomalies',
                    'Anomaly Severity Analysis',
                    'Anomaly Patterns',
                    'Performance Metrics'
                ),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # 1. Price with Anomaly Detection
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=df['close'],
                    mode='lines',
                    name='Price',
                    line=dict(color='lightblue', width=2)
                ),
                row=1, col=1
            )
            
            # Highlight anomalies
            anomaly_dates = df.index[anomaly_flags]
            anomaly_prices = df['close'][anomaly_flags]
            
            fig.add_trace(
                go.Scatter(
                    x=anomaly_dates,
                    y=anomaly_prices,
                    mode='markers',
                    name='Anomalies',
                    marker=dict(
                        color='red',
                        size=12,
                        symbol='x',
                        line=dict(width=2, color='darkred')
                    )
                ),
                row=1, col=1
            )
            
            # Add confidence bands
            confidence_upper = df['close'] * 1.05
            confidence_lower = df['close'] * 0.95
            
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=confidence_upper,
                    mode='lines',
                    line=dict(width=0),
                    showlegend=False,
                    hoverinfo='skip'
                ),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=confidence_lower,
                    mode='lines',
                    line=dict(width=0),
                    fill='tonexty',
                    fillcolor='rgba(0,100,80,0.1)',
                    name='Confidence Band',
                    hoverinfo='skip'
                ),
                row=1, col=1
            )
            
            # 2. Anomaly Score Timeline
            fig.add_trace(
                go.Scatter(
                    x=df.index,
                    y=anomaly_scores,
                    mode='lines+markers',
                    name='Anomaly Score',
                    line=dict(color='orange', width=2),
                    marker=dict(size=4)
                ),
                row=1, col=2
            )
            
            # Add threshold lines
            thresholds = [0.3, 0.5, 0.7]
            colors = ['green', 'yellow', 'red']
            for threshold, color in zip(thresholds, colors):
                fig.add_hline(
                    y=threshold,
                    line_dash="dash",
                    line_color=color,
                    annotation_text=f"Threshold: {threshold}",
                    row=1, col=2
                )
            
            # 3. Anomaly Distribution
            fig.add_trace(
                go.Histogram(
                    x=anomaly_scores,
                    name='Anomaly Score Distribution',
                    nbinsx=20,
                    marker_color='lightgreen',
                    opacity=0.7
                ),
                row=2, col=1
            )
            
            # Add normal distribution overlay
            mu, sigma = np.mean(anomaly_scores), np.std(anomaly_scores)
            x_norm = np.linspace(min(anomaly_scores), max(anomaly_scores), 100)
            y_norm = (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x_norm - mu) / sigma) ** 2)
            
            fig.add_trace(
                go.Scatter(
                    x=x_norm,
                    y=y_norm,
                    mode='lines',
                    name='Normal Distribution',
                    line=dict(color='red', width=2, dash='dash')
                ),
                row=2, col=1
            )
            
            # 4. Anomaly Clustering
            features = self._extract_anomaly_features(df)
            if features is not None and len(features) > 0:
                # Create 2D projection for clustering visualization
                x_proj = features[:, 0] if features.shape[1] > 0 else np.arange(len(features))
                y_proj = features[:, 1] if features.shape[1] > 1 else anomaly_scores
                
                # Color by anomaly type if available
                if anomaly_types:
                    unique_types = list(set(anomaly_types))
                    colors = px.colors.qualitative.Set3[:len(unique_types)]
                    color_map = {t: colors[i] for i, t in enumerate(unique_types)}
                    marker_colors = [color_map.get(t, 'blue') for t in anomaly_types]
                else:
                    marker_colors = ['red' if flag else 'blue' for flag in anomaly_flags]
                
                fig.add_trace(
                    go.Scatter(
                        x=x_proj,
                        y=y_proj,
                        mode='markers',
                        name='Data Points',
                        marker=dict(
                            color=marker_colors,
                            size=8,
                            opacity=0.6
                        ),
                        text=[f'Day {i+1}' for i in range(len(df))],
                        hovertemplate='<b>%{text}</b><br>Anomaly: %{marker.color}<extra></extra>'
                    ),
                    row=2, col=2
                )
            
            # 5. Volatility vs Anomalies
            volatility = df['close'].pct_change().rolling(10).std()
            fig.add_trace(
                go.Scatter(
                    x=volatility,
                    y=anomaly_scores,
                    mode='markers',
                    name='Volatility vs Anomaly',
                    marker=dict(
                        color=anomaly_scores,
                        size=8,
                        colorscale='Reds',
                        showscale=True,
                        colorbar=dict(title="Anomaly Score")
                    )
                ),
                row=3, col=1
            )
            
            # Add trend line
            z = np.polyfit(volatility.dropna(), np.array(anomaly_scores)[~volatility.isna()], 1)
            p = np.poly1d(z)
            fig.add_trace(
                go.Scatter(
                    x=volatility.dropna(),
                    y=p(volatility.dropna()),
                    mode='lines',
                    name='Trend Line',
                    line=dict(color='blue', width=2, dash='dash')
                ),
                row=3, col=1
            )
            
            # 6. Anomaly Severity Analysis
            severity_levels = self._classify_anomaly_severity(anomaly_scores)
            severity_counts = {level: severity_levels.count(level) for level in set(severity_levels)}
            
            fig.add_trace(
                go.Bar(
                    x=list(severity_counts.keys()),
                    y=list(severity_counts.values()),
                    name='Anomaly Severity',
                    marker_color=['green', 'yellow', 'orange', 'red'][:len(severity_counts)],
                    text=list(severity_counts.values()),
                    textposition='auto'
                ),
                row=3, col=2
            )
            
            # 7. Anomaly Patterns (time-based)
            hourly_patterns = self._analyze_hourly_patterns(df, anomaly_flags)
            if hourly_patterns:
                fig.add_trace(
                    go.Bar(
                        x=list(hourly_patterns.keys()),
                        y=list(hourly_patterns.values()),
                        name='Hourly Anomaly Pattern',
                        marker_color='lightcoral'
                    ),
                    row=4, col=1
                )
            
            # 8. Performance Metrics
            performance_metrics = self._calculate_anomaly_performance_metrics(
                anomaly_scores, anomaly_flags, df
            )
            
            metrics_names = list(performance_metrics.keys())
            metrics_values = list(performance_metrics.values())
            
            fig.add_trace(
                go.Bar(
                    x=metrics_names,
                    y=metrics_values,
                    name='Performance Metrics',
                    marker_color='lightblue',
                    text=[f'{val:.3f}' for val in metrics_values],
                    textposition='auto'
                ),
                row=4, col=2
            )
            
            # Update layout
            fig.update_layout(
                title=f'{ticker} Comprehensive Anomaly Detection Analysis',
                height=1600,
                showlegend=True,
                template='plotly_white'
            )
            
            # Save visualization
            filename = f"{self.output_dir}/{ticker}_comprehensive_anomaly_analysis.html"
            fig.write_html(filename)
            
            print(f"‚úÖ Comprehensive anomaly analysis saved: {filename}")
            return filename
            
        except Exception as e:
            print(f"‚ùå Comprehensive anomaly analysis failed: {str(e)}")
            return ""
    
    def create_real_time_anomaly_monitor(self, ticker: str, live_data: Dict[str, Any]) -> str:
        """
        Create real-time anomaly monitoring dashboard
        
        Args:
            ticker: Stock ticker symbol
            live_data: Real-time data dictionary
            
        Returns:
            Path to saved visualization
        """
        try:
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=(
                    'Real-Time Price & Anomalies',
                    'Anomaly Score Stream',
                    'Anomaly Alert Timeline',
                    'Risk Assessment',
                    'Anomaly Clusters',
                    'System Status'
                ),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # 1. Real-Time Price & Anomalies
            if 'price_data' in live_data:
                price_data = live_data['price_data']
                fig.add_trace(
                    go.Scatter(
                        x=price_data['timestamps'],
                        y=price_data['prices'],
                        mode='lines+markers',
                        name='Price',
                        line=dict(color='blue', width=2)
                    ),
                    row=1, col=1
                )
                
                # Highlight anomalies
                if 'anomaly_flags' in live_data:
                    anomaly_flags = live_data['anomaly_flags']
                    anomaly_times = [price_data['timestamps'][i] for i, flag in enumerate(anomaly_flags) if flag]
                    anomaly_prices = [price_data['prices'][i] for i, flag in enumerate(anomaly_flags) if flag]
                    
                    fig.add_trace(
                        go.Scatter(
                            x=anomaly_times,
                            y=anomaly_prices,
                            mode='markers',
                            name='Anomalies',
                            marker=dict(
                                color='red',
                                size=12,
                                symbol='x'
                            )
                        ),
                        row=1, col=1
                    )
            
            # 2. Anomaly Score Stream
            if 'anomaly_scores' in live_data:
                scores = live_data['anomaly_scores']
                timestamps = live_data.get('timestamps', list(range(len(scores))))
                
                fig.add_trace(
                    go.Scatter(
                        x=timestamps,
                        y=scores,
                        mode='lines+markers',
                        name='Anomaly Score',
                        line=dict(color='orange', width=2)
                    ),
                    row=1, col=2
                )
                
                # Add threshold line
                threshold = live_data.get('threshold', 0.5)
                fig.add_hline(
                    y=threshold,
                    line_dash="dash",
                    line_color="red",
                    annotation_text=f"Threshold: {threshold}",
                    row=1, col=2
                )
            
            # 3. Anomaly Alert Timeline
            if 'alerts' in live_data:
                alerts = live_data['alerts']
                alert_times = [alert['timestamp'] for alert in alerts]
                alert_severities = [alert['severity'] for alert in alerts]
                
                colors = {'LOW': 'green', 'MEDIUM': 'yellow', 'HIGH': 'orange', 'CRITICAL': 'red'}
                marker_colors = [colors.get(severity, 'blue') for severity in alert_severities]
                
                fig.add_trace(
                    go.Scatter(
                        x=alert_times,
                        y=alert_severities,
                        mode='markers',
                        name='Alerts',
                        marker=dict(
                            color=marker_colors,
                            size=12,
                            symbol='triangle-up'
                        )
                    ),
                    row=2, col=1
                )
            
            # 4. Risk Assessment
            risk_levels = self._assess_risk_levels(live_data)
            if risk_levels:
                fig.add_trace(
                    go.Bar(
                        x=list(risk_levels.keys()),
                        y=list(risk_levels.values()),
                        name='Risk Assessment',
                        marker_color=['green', 'yellow', 'orange', 'red'][:len(risk_levels)]
                    ),
                    row=2, col=2
                )
            
            # 5. Anomaly Clusters
            if 'anomaly_clusters' in live_data:
                clusters = live_data['anomaly_clusters']
                fig.add_trace(
                    go.Scatter(
                        x=clusters['x'],
                        y=clusters['y'],
                        mode='markers',
                        name='Anomaly Clusters',
                        marker=dict(
                            color=clusters['labels'],
                            size=8,
                            colorscale='Viridis'
                        )
                    ),
                    row=3, col=1
                )
            
            # 6. System Status
            system_status = self._get_system_status(live_data)
            status_names = list(system_status.keys())
            status_values = list(system_status.values())
            
            fig.add_trace(
                go.Bar(
                    x=status_names,
                    y=status_values,
                    name='System Status',
                    marker_color='lightblue'
                ),
                row=3, col=2
            )
            
            # Update layout
            fig.update_layout(
                title=f'{ticker} Real-Time Anomaly Monitor',
                height=1200,
                showlegend=True,
                template='plotly_white'
            )
            
            # Save visualization
            filename = f"{self.output_dir}/{ticker}_realtime_anomaly_monitor.html"
            fig.write_html(filename)
            
            print(f"‚úÖ Real-time anomaly monitor saved: {filename}")
            return filename
            
        except Exception as e:
            print(f"‚ùå Real-time anomaly monitor failed: {str(e)}")
            return ""
    
    def create_anomaly_pattern_analysis(self, ticker: str, df: pd.DataFrame, 
                                      anomaly_data: Dict[str, Any]) -> str:
        """
        Create anomaly pattern analysis visualization
        
        Args:
            ticker: Stock ticker symbol
            df: Historical data
            anomaly_data: Anomaly detection results
            
        Returns:
            Path to saved visualization
        """
        try:
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=(
                    'Anomaly Frequency by Time',
                    'Anomaly Magnitude Distribution',
                    'Anomaly Correlation Matrix',
                    'Anomaly Trend Analysis',
                    'Anomaly Seasonality',
                    'Anomaly Impact Analysis'
                ),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # 1. Anomaly Frequency by Time
            hourly_anomalies = self._analyze_hourly_anomaly_patterns(df, anomaly_data)
            if hourly_anomalies:
                fig.add_trace(
                    go.Bar(
                        x=list(hourly_anomalies.keys()),
                        y=list(hourly_anomalies.values()),
                        name='Hourly Anomaly Frequency',
                        marker_color='lightcoral'
                    ),
                    row=1, col=1
                )
            
            # 2. Anomaly Magnitude Distribution
            if 'anomaly_scores' in anomaly_data:
                scores = anomaly_data['anomaly_scores']
                fig.add_trace(
                    go.Histogram(
                        x=scores,
                        name='Anomaly Magnitude',
                        nbinsx=20,
                        marker_color='lightgreen',
                        opacity=0.7
                    ),
                    row=1, col=2
                )
            
            # 3. Anomaly Correlation Matrix
            correlation_data = self._calculate_anomaly_correlations(df, anomaly_data)
            if correlation_data is not None:
                fig.add_trace(
                    go.Heatmap(
                        z=correlation_data['matrix'],
                        x=correlation_data['features'],
                        y=correlation_data['features'],
                        colorscale='RdBu',
                        name='Correlation Matrix'
                    ),
                    row=2, col=1
                )
            
            # 4. Anomaly Trend Analysis
            trend_data = self._analyze_anomaly_trends(df, anomaly_data)
            if trend_data:
                fig.add_trace(
                    go.Scatter(
                        x=trend_data['dates'],
                        y=trend_data['anomaly_counts'],
                        mode='lines+markers',
                        name='Anomaly Trend',
                        line=dict(color='blue', width=2)
                    ),
                    row=2, col=2
                )
            
            # 5. Anomaly Seasonality
            seasonal_data = self._analyze_anomaly_seasonality(df, anomaly_data)
            if seasonal_data:
                fig.add_trace(
                    go.Scatter(
                        x=seasonal_data['periods'],
                        y=seasonal_data['anomaly_rates'],
                        mode='lines+markers',
                        name='Seasonal Anomaly Rate',
                        line=dict(color='purple', width=2)
                    ),
                    row=3, col=1
                )
            
            # 6. Anomaly Impact Analysis
            impact_data = self._analyze_anomaly_impact(df, anomaly_data)
            if impact_data:
                fig.add_trace(
                    go.Bar(
                        x=list(impact_data.keys()),
                        y=list(impact_data.values()),
                        name='Anomaly Impact',
                        marker_color='orange'
                    ),
                    row=3, col=2
                )
            
            # Update layout
            fig.update_layout(
                title=f'{ticker} Anomaly Pattern Analysis',
                height=1200,
                showlegend=True,
                template='plotly_white'
            )
            
            # Save visualization
            filename = f"{self.output_dir}/{ticker}_anomaly_pattern_analysis.html"
            fig.write_html(filename)
            
            print(f"‚úÖ Anomaly pattern analysis saved: {filename}")
            return filename
            
        except Exception as e:
            print(f"‚ùå Anomaly pattern analysis failed: {str(e)}")
            return ""
    
    def _extract_anomaly_features(self, df: pd.DataFrame) -> Optional[np.ndarray]:
        """Extract features for anomaly analysis"""
        try:
            features = []
            
            # Price-based features
            features.append(df['close'].pct_change().fillna(0).values)
            features.append(df['close'].rolling(5).mean().pct_change().fillna(0).values)
            features.append(df['close'].rolling(20).mean().pct_change().fillna(0).values)
            
            # Volatility features
            features.append(df['close'].pct_change().rolling(5).std().fillna(0).values)
            features.append(df['close'].pct_change().rolling(20).std().fillna(0).values)
            
            # Volume features if available
            if 'volume' in df.columns:
                features.append(df['volume'].pct_change().fillna(0).values)
                features.append(df['volume'].rolling(10).mean().pct_change().fillna(0).values)
            
            # Technical indicators
            rsi = self._calculate_rsi(df['close']).fillna(50).values
            features.append((rsi - 50) / 50)  # Normalize RSI
            
            # Combine features
            feature_matrix = np.column_stack(features)
            return feature_matrix
            
        except Exception as e:
            return None
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """Calculate RSI indicator"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = (-delta).where(delta < 0, 0).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _classify_anomaly_severity(self, anomaly_scores: List[float]) -> List[str]:
        """Classify anomaly severity levels"""
        severity_levels = []
        for score in anomaly_scores:
            if score >= 0.8:
                severity_levels.append('CRITICAL')
            elif score >= 0.6:
                severity_levels.append('HIGH')
            elif score >= 0.4:
                severity_levels.append('MEDIUM')
            else:
                severity_levels.append('LOW')
        return severity_levels
    
    def _analyze_hourly_patterns(self, df: pd.DataFrame, anomaly_flags: List[bool]) -> Dict[str, int]:
        """Analyze hourly anomaly patterns"""
        try:
            hourly_anomalies = {}
            for i, (timestamp, is_anomaly) in enumerate(zip(df.index, anomaly_flags)):
                if is_anomaly:
                    hour = timestamp.hour
                    hourly_anomalies[hour] = hourly_anomalies.get(hour, 0) + 1
            return hourly_anomalies
        except Exception:
            return {}
    
    def _calculate_anomaly_performance_metrics(self, anomaly_scores: List[float], 
                                            anomaly_flags: List[bool], 
                                            df: pd.DataFrame) -> Dict[str, float]:
        """Calculate anomaly detection performance metrics"""
        try:
            # Basic metrics
            total_anomalies = sum(anomaly_flags)
            total_points = len(anomaly_flags)
            anomaly_rate = total_anomalies / total_points if total_points > 0 else 0
            
            # Score statistics
            avg_score = np.mean(anomaly_scores)
            max_score = np.max(anomaly_scores)
            min_score = np.min(anomaly_scores)
            std_score = np.std(anomaly_scores)
            
            # Volatility correlation
            volatility = df['close'].pct_change().rolling(10).std()
            volatility_correlation = np.corrcoef(anomaly_scores, volatility.fillna(0))[0, 1]
            
            return {
                'Anomaly Rate': anomaly_rate,
                'Avg Score': avg_score,
                'Max Score': max_score,
                'Min Score': min_score,
                'Score Std': std_score,
                'Volatility Correlation': volatility_correlation
            }
        except Exception:
            return {}
    
    def _assess_risk_levels(self, live_data: Dict[str, Any]) -> Dict[str, int]:
        """Assess current risk levels"""
        try:
            risk_levels = {'LOW': 0, 'MEDIUM': 0, 'HIGH': 0, 'CRITICAL': 0}
            
            if 'anomaly_scores' in live_data:
                scores = live_data['anomaly_scores']
                for score in scores:
                    if score >= 0.8:
                        risk_levels['CRITICAL'] += 1
                    elif score >= 0.6:
                        risk_levels['HIGH'] += 1
                    elif score >= 0.4:
                        risk_levels['MEDIUM'] += 1
                    else:
                        risk_levels['LOW'] += 1
            
            return risk_levels
        except Exception:
            return {}
    
    def _get_system_status(self, live_data: Dict[str, Any]) -> Dict[str, float]:
        """Get system status metrics"""
        try:
            status = {
                'Data Quality': 0.95,
                'Model Accuracy': 0.87,
                'Processing Speed': 0.92,
                'Alert System': 0.89,
                'Data Coverage': 0.94
            }
            
            # Update based on live data
            if 'anomaly_scores' in live_data:
                scores = live_data['anomaly_scores']
                if len(scores) > 0:
                    status['Model Accuracy'] = 1.0 - np.mean(scores)
            
            return status
        except Exception:
            return {}
    
    def _analyze_hourly_anomaly_patterns(self, df: pd.DataFrame, anomaly_data: Dict[str, Any]) -> Dict[str, int]:
        """Analyze hourly anomaly patterns"""
        try:
            hourly_anomalies = {}
            if 'anomaly_flags' in anomaly_data:
                flags = anomaly_data['anomaly_flags']
                for i, (timestamp, is_anomaly) in enumerate(zip(df.index, flags)):
                    if is_anomaly:
                        hour = timestamp.hour
                        hourly_anomalies[hour] = hourly_anomalies.get(hour, 0) + 1
            return hourly_anomalies
        except Exception:
            return {}
    
    def _calculate_anomaly_correlations(self, df: pd.DataFrame, anomaly_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Calculate anomaly correlations"""
        try:
            features = self._extract_anomaly_features(df)
            if features is None:
                return None
            
            # Calculate correlation matrix
            correlation_matrix = np.corrcoef(features.T)
            
            feature_names = ['Price Change', 'SMA5 Change', 'SMA20 Change', 'Volatility5', 'Volatility20']
            if 'volume' in df.columns:
                feature_names.extend(['Volume Change', 'Volume SMA'])
            feature_names.append('RSI')
            
            return {
                'matrix': correlation_matrix,
                'features': feature_names[:correlation_matrix.shape[0]]
            }
        except Exception:
            return None
    
    def _analyze_anomaly_trends(self, df: pd.DataFrame, anomaly_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Analyze anomaly trends over time"""
        try:
            if 'anomaly_flags' not in anomaly_data:
                return None
            
            # Group by date and count anomalies
            daily_anomalies = {}
            for i, (date, is_anomaly) in enumerate(zip(df.index, anomaly_data['anomaly_flags'])):
                date_key = date.date()
                if date_key not in daily_anomalies:
                    daily_anomalies[date_key] = 0
                if is_anomaly:
                    daily_anomalies[date_key] += 1
            
            return {
                'dates': list(daily_anomalies.keys()),
                'anomaly_counts': list(daily_anomalies.values())
            }
        except Exception:
            return None
    
    def _analyze_anomaly_seasonality(self, df: pd.DataFrame, anomaly_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Analyze anomaly seasonality"""
        try:
            if 'anomaly_flags' not in anomaly_data:
                return None
            
            # Analyze by day of week
            daily_anomalies = {}
            for i, (date, is_anomaly) in enumerate(zip(df.index, anomaly_data['anomaly_flags'])):
                day_of_week = date.dayofweek
                if day_of_week not in daily_anomalies:
                    daily_anomalies[day_of_week] = {'anomalies': 0, 'total': 0}
                daily_anomalies[day_of_week]['total'] += 1
                if is_anomaly:
                    daily_anomalies[day_of_week]['anomalies'] += 1
            
            periods = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            anomaly_rates = []
            for day in range(7):
                if day in daily_anomalies:
                    rate = daily_anomalies[day]['anomalies'] / daily_anomalies[day]['total']
                    anomaly_rates.append(rate)
                else:
                    anomaly_rates.append(0)
            
            return {
                'periods': periods,
                'anomaly_rates': anomaly_rates
            }
        except Exception:
            return None
    
    def _analyze_anomaly_impact(self, df: pd.DataFrame, anomaly_data: Dict[str, Any]) -> Dict[str, float]:
        """Analyze anomaly impact on price"""
        try:
            impact_metrics = {
                'Price Impact': 0.0,
                'Volatility Impact': 0.0,
                'Volume Impact': 0.0,
                'Trend Impact': 0.0
            }
            
            if 'anomaly_flags' not in anomaly_data:
                return impact_metrics
            
            # Calculate impact metrics
            anomaly_days = df[anomaly_data['anomaly_flags']]
            normal_days = df[~np.array(anomaly_data['anomaly_flags'])]
            
            if len(anomaly_days) > 0 and len(normal_days) > 0:
                # Price impact
                anomaly_returns = anomaly_days['close'].pct_change().mean()
                normal_returns = normal_days['close'].pct_change().mean()
                impact_metrics['Price Impact'] = abs(anomaly_returns - normal_returns)
                
                # Volatility impact
                anomaly_vol = anomaly_days['close'].pct_change().std()
                normal_vol = normal_days['close'].pct_change().std()
                impact_metrics['Volatility Impact'] = abs(anomaly_vol - normal_vol)
                
                # Volume impact
                if 'volume' in df.columns:
                    anomaly_volume = anomaly_days['volume'].mean()
                    normal_volume = normal_days['volume'].mean()
                    impact_metrics['Volume Impact'] = abs(anomaly_volume - normal_volume) / normal_volume
            
            return impact_metrics
        except Exception:
            return {}

def main():
    """Main function to demonstrate anomaly detection visualizer"""
    print("üîç Starting Anomaly Detection Visualizer")
    print("=" * 60)
    
    # Initialize visualizer
    visualizer = AnomalyDetectionVisualizer()
    
    # Create sample data for demonstration
    dates = pd.date_range(start='2024-01-01', end='2024-01-30', freq='D')
    np.random.seed(42)
    
    # Sample price data with some anomalies
    base_price = 100
    prices = [base_price]
    for i in range(1, len(dates)):
        # Create some artificial anomalies
        if i % 7 == 0:  # Weekly anomalies
            change = np.random.normal(0, 0.05)  # Higher volatility
        else:
            change = np.random.normal(0, 0.02)
        prices.append(prices[-1] * (1 + change))
    
    # Create OHLCV data
    df = pd.DataFrame({
        'open': [p * (1 + np.random.normal(0, 0.01)) for p in prices],
        'high': [p * (1 + abs(np.random.normal(0, 0.02))) for p in prices],
        'low': [p * (1 - abs(np.random.normal(0, 0.02))) for p in prices],
        'close': prices,
        'volume': np.random.randint(1000, 10000, len(dates))
    }, index=dates)
    
    # Generate anomaly data
    anomaly_scores = np.random.random(len(dates))
    anomaly_flags = anomaly_scores > 0.7  # 30% anomaly rate
    anomaly_types = ['Price', 'Volume', 'Volatility', 'Trend'][np.random.randint(0, 4, len(dates))]
    
    # Create visualizations
    print("üìä Creating anomaly detection visualizations...")
    
    # 1. Comprehensive Anomaly Analysis
    comprehensive_path = visualizer.create_comprehensive_anomaly_analysis(
        'DEMO', df, anomaly_scores, anomaly_flags, anomaly_types
    )
    
    # 2. Real-Time Anomaly Monitor (sample data)
    live_data = {
        'price_data': {
            'timestamps': dates,
            'prices': prices
        },
        'anomaly_scores': anomaly_scores,
        'anomaly_flags': anomaly_flags,
        'threshold': 0.5,
        'alerts': [
            {'timestamp': dates[i], 'severity': 'HIGH'} 
            for i, flag in enumerate(anomaly_flags) if flag
        ]
    }
    
    monitor_path = visualizer.create_real_time_anomaly_monitor('DEMO', live_data)
    
    # 3. Anomaly Pattern Analysis
    anomaly_data = {
        'anomaly_scores': anomaly_scores,
        'anomaly_flags': anomaly_flags,
        'anomaly_types': anomaly_types
    }
    
    pattern_path = visualizer.create_anomaly_pattern_analysis('DEMO', df, anomaly_data)
    
    print("\n‚úÖ Anomaly detection visualizer demonstration completed!")
    print(f"üìÅ All visualizations saved in: {visualizer.output_dir}")
    
    return [comprehensive_path, monitor_path, pattern_path]

if __name__ == "__main__":
    visualizations = main()
