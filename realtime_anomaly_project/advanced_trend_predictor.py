"""
Advanced Trend Prediction System for 99.8%+ Accuracy
Implements state-of-the-art models:
- XGBoost with advanced hyperparameter optimization
- LightGBM for gradient boosting
- LSTM for time series modeling
- Facebook Prophet for trend analysis
- Advanced ensemble methods
- Comprehensive evaluation metrics (F1, Precision, Recall)
"""

import os
import sys
import importlib
import numpy as np
import pandas as pd
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any, Union, TYPE_CHECKING
import warnings
warnings.filterwarnings('ignore')

# Type checking imports - only used by type checker, not at runtime
if TYPE_CHECKING:
    # Suppress import errors for optional dependencies
    pass

# Utility function for safe array conversion
def safe_array_conversion(predictions) -> np.ndarray:
    """Safely convert predictions to numpy array for sklearn metrics"""
    if hasattr(predictions, 'toarray'):
        # Handle sparse matrices
        return predictions.toarray().flatten()
    elif isinstance(predictions, list):
        return np.array(predictions).flatten()
    else:
        # Already numpy array or similar
        return np.asarray(predictions).flatten()

# Advanced ML libraries
try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except ImportError:
    print("Warning: XGBoost not available")
    XGB_AVAILABLE = False
    xgb = None

# Advanced ML libraries with proper type handling
try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except ImportError:
    print("Warning: XGBoost not available")
    XGB_AVAILABLE = False
    # Create a mock module to avoid type checker warnings
    class MockXGBoost:
        class XGBClassifier:
            def __init__(self, **kwargs): pass
            def fit(self, *args, **kwargs): pass
            def predict(self, *args, **kwargs): return None
    xgb = MockXGBoost()

try:
    import lightgbm as lgb
    LGB_AVAILABLE = True
except ImportError:
    print("Warning: LightGBM not available")
    LGB_AVAILABLE = False
    # Create a mock module to avoid type checker warnings
    class MockLightGBM:
        class LGBMClassifier:
            def __init__(self, **kwargs): pass
            def fit(self, *args, **kwargs): pass
            def predict(self, *args, **kwargs): return None
        @staticmethod
        def early_stopping(*args, **kwargs): return None
        @staticmethod
        def log_evaluation(*args, **kwargs): return None
    lgb = MockLightGBM()

# CatBoost dynamic imports to avoid static type checking issues
def _import_catboost():
    """Dynamically import CatBoost to avoid static import analysis type issues."""
    try:
        catboost_module = importlib.import_module('catboost')
        return {
            'CatBoostClassifier': getattr(catboost_module, 'CatBoostClassifier'),
            'CatBoostRegressor': getattr(catboost_module, 'CatBoostRegressor'),
            'available': True
        }
    except ImportError:
        print("Warning: CatBoost not available")
        # Create mock classes
        class CatBoostClassifier:
            def __init__(self, **kwargs): pass
            def fit(self, *args, **kwargs): pass
            def predict(self, *args, **kwargs): return None
        class CatBoostRegressor:
            def __init__(self, **kwargs): pass
            def fit(self, *args, **kwargs): pass
            def predict(self, *args, **kwargs): return None
        
        return {
            'CatBoostClassifier': CatBoostClassifier,
            'CatBoostRegressor': CatBoostRegressor,
            'available': False
        }

# Initialize CatBoost
_catboost_imports = _import_catboost()
CatBoostClassifier = _catboost_imports['CatBoostClassifier']
CatBoostRegressor = _catboost_imports['CatBoostRegressor']
CATBOOST_AVAILABLE = _catboost_imports['available']

# TensorFlow imports with proper type handling
TF_AVAILABLE = False
tf = None
Sequential = None
Model = None
LSTM = None
Dense = None
Dropout = None
BatchNormalization = None
Input = None
Attention = None
MultiHeadAttention = None
Adam = None
EarlyStopping = None
ReduceLROnPlateau = None

# Dynamic import without static import statements to avoid type checker warnings
def _import_tensorflow():
    global TF_AVAILABLE, tf, Sequential, Model, LSTM, Dense, Dropout, BatchNormalization
    global Input, Attention, MultiHeadAttention, Adam, EarlyStopping, ReduceLROnPlateau
    
    try:
        # Use importlib to avoid static import analysis
        import importlib
        tf_module = importlib.import_module('tensorflow')
        tf = tf_module
        
        # Check if tensorflow is properly installed
        if hasattr(tf_module, 'keras'):
            keras_models = importlib.import_module('tensorflow.keras.models')
            keras_layers = importlib.import_module('tensorflow.keras.layers')
            keras_optimizers = importlib.import_module('tensorflow.keras.optimizers')
            keras_callbacks = importlib.import_module('tensorflow.keras.callbacks')
            
            Sequential = keras_models.Sequential
            Model = keras_models.Model
            LSTM = keras_layers.LSTM
            Dense = keras_layers.Dense
            Dropout = keras_layers.Dropout
            BatchNormalization = keras_layers.BatchNormalization
            Input = keras_layers.Input
            Attention = keras_layers.Attention
            MultiHeadAttention = keras_layers.MultiHeadAttention
            Adam = keras_optimizers.Adam
            EarlyStopping = keras_callbacks.EarlyStopping
            ReduceLROnPlateau = keras_callbacks.ReduceLROnPlateau
            TF_AVAILABLE = True
        else:
            raise ImportError("TensorFlow keras module not available")
    except ImportError:
        print("Warning: TensorFlow not available")
        TF_AVAILABLE = False
        tf = None
        # Create mock classes that won't trigger type errors
        class MockClass:
            def __init__(self, *args, **kwargs): pass
            def __call__(self, *args, **kwargs): return self
            def compile(self, *args, **kwargs): pass
            def fit(self, *args, **kwargs): return None
            def predict(self, *args, **kwargs): return None
        
        Sequential = MockClass()
        Model = MockClass()
        LSTM = MockClass()
        Dense = MockClass()
        Dropout = MockClass()
        BatchNormalization = MockClass()
        Input = MockClass()
        Attention = MockClass()
        MultiHeadAttention = MockClass()
        Adam = MockClass()
        EarlyStopping = MockClass()
        ReduceLROnPlateau = MockClass()

# Initialize TensorFlow on import
_import_tensorflow()
from sklearn.ensemble import VotingClassifier, VotingRegressor, StackingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.model_selection import cross_val_score, StratifiedKFold, TimeSeriesSplit, train_test_split
import optuna
from optuna.samplers import TPESampler
from optuna.pruners import MedianPruner

# Time series specific
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    logging.warning("Prophet not available. Install with: pip install prophet")

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

logger = logging.getLogger(__name__)

class AdvancedTrendPredictor:
    """Advanced trend prediction system targeting 99.8%+ accuracy"""
    
    def __init__(self, target_accuracy: float = 0.998, use_gpu: bool = True):
        self.target_accuracy = target_accuracy
        self.use_gpu = use_gpu and TF_AVAILABLE and tf is not None and tf.config.list_physical_devices('GPU')
        self.models = {}
        self.ensemble_model = None
        self.feature_importance = {}
        self.performance_metrics = {}
        
        # Configure GPU for TensorFlow
        if self.use_gpu and TF_AVAILABLE and tf is not None:
            try:
                gpus = tf.config.experimental.list_physical_devices('GPU')
                if gpus:
                    tf.config.experimental.set_memory_growth(gpus[0], True)
                    logger.info(f"GPU enabled for TensorFlow: {gpus[0].name}")
            except Exception as e:
                logger.warning(f"Failed to configure GPU for TensorFlow: {e}")
                self.use_gpu = False
        elif self.use_gpu and not TF_AVAILABLE:
            logger.warning("TensorFlow not available - GPU acceleration disabled")
            self.use_gpu = False
        
        logger.info(f"Advanced Trend Predictor initialized. Target accuracy: {target_accuracy:.1%}")
    
    def create_lstm_model(self, input_shape: Tuple[int, int], num_classes: int = 2):
        """Create advanced LSTM model with attention mechanism"""
        if not TF_AVAILABLE or tf is None:
            logger.warning("TensorFlow not available - LSTM model creation skipped")
            return None
            
        try:
            # Use tf.keras instead of separate imports to avoid import resolution issues
            Sequential = tf.keras.models.Sequential
            LSTM = tf.keras.layers.LSTM
            Dense = tf.keras.layers.Dense
            Dropout = tf.keras.layers.Dropout
            Adam = tf.keras.optimizers.Adam
            
            model = Sequential([
                LSTM(128, return_sequences=True, input_shape=input_shape),
                Dropout(0.3),
                LSTM(64, return_sequences=False),
                Dropout(0.3),
                Dense(32, activation='relu'),
                Dense(1, activation='sigmoid')  # Binary classification
            ])
            
            model.compile(
                optimizer=Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy']
            )
            
            logger.info(f"LSTM model created with input shape {input_shape}")
            return model
            
        except Exception as e:
            logger.error(f"Failed to create LSTM model: {str(e)}")
            return None
    def optimize_xgboost_hyperparameters(self, X_train: np.ndarray, y_train: np.ndarray, 
                                       X_val: np.ndarray, y_val: np.ndarray, 
                                       n_trials: int = 50) -> Dict[str, Any]:
        """Optimize XGBoost hyperparameters using Optuna"""
        
        if not XGB_AVAILABLE or xgb is None:
            logger.warning("XGBoost not available - returning default parameters")
            return {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}
        
        def objective(trial):
            params = {
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                'max_depth': trial.suggest_int('max_depth', 3, 12),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'gamma': trial.suggest_float('gamma', 0, 5),
                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
                'random_state': 42,
                'verbosity': 0,
                'n_jobs': -1
            }
            
            # Add GPU support if available
            if self.use_gpu:
                params['tree_method'] = 'gpu_hist'
                params['gpu_id'] = 0
            
            # Train model
            model = xgb.XGBClassifier(**params)  # type: ignore[attr-defined]
            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, early_stopping_rounds=10)
            
            # Predict and calculate accuracy
            y_pred = model.predict(X_val)
            y_pred_safe = safe_array_conversion(y_pred)
            accuracy = accuracy_score(y_val, y_pred_safe)
            
            return float(accuracy)
        
        logger.info("Optimizing XGBoost hyperparameters...")
        study = optuna.create_study(direction='maximize', 
                                  sampler=TPESampler(seed=42),
                                  pruner=MedianPruner())
        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
        
        best_params = study.best_params
        best_params['objective'] = 'binary:logistic'
        best_params['eval_metric'] = 'logloss'
        best_params['random_state'] = 42
        best_params['verbosity'] = 0
        best_params['n_jobs'] = -1
        
        if self.use_gpu:
            best_params['tree_method'] = 'gpu_hist'
            best_params['gpu_id'] = 0
        
        logger.info(f"XGBoost optimization complete. Best accuracy: {study.best_value:.4f}")
        return best_params
    
    def optimize_lightgbm_hyperparameters(self, X_train: np.ndarray, y_train: np.ndarray,
                                        X_val: np.ndarray, y_val: np.ndarray,
                                        n_trials: int = 50) -> Dict[str, Any]:
        """Optimize LightGBM hyperparameters using Optuna"""
        
        if not LGB_AVAILABLE or lgb is None:
            logger.warning("LightGBM not available - returning default parameters")
            return {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}
        
        def objective(trial):
            params = {
                'objective': 'binary',
                'metric': 'binary_logloss',
                'boosting_type': 'gbdt',
                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                'max_depth': trial.suggest_int('max_depth', 3, 12),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'num_leaves': trial.suggest_int('num_leaves', 10, 300),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
                'random_state': 42,
                'verbosity': -1,
                'n_jobs': -1
            }
            
            # Add GPU support if available
            if self.use_gpu:
                params['device'] = 'gpu'
                params['gpu_platform_id'] = 0
                params['gpu_device_id'] = 0
            
            # Train model
            model = lgb.LGBMClassifier(**params)  # type: ignore[attr-defined]
            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)])  # type: ignore[attr-defined]
            
            # Predict and calculate accuracy
            y_pred = model.predict(X_val)
            y_pred_safe = safe_array_conversion(y_pred)
            accuracy = accuracy_score(y_val, y_pred_safe)
            
            return float(accuracy)
        
        logger.info("Optimizing LightGBM hyperparameters...")
        study = optuna.create_study(direction='maximize',
                                  sampler=TPESampler(seed=42),
                                  pruner=MedianPruner())
        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
        
        best_params = study.best_params
        best_params['objective'] = 'binary'
        best_params['metric'] = 'binary_logloss'
        best_params['boosting_type'] = 'gbdt'
        best_params['random_state'] = 42
        best_params['verbosity'] = -1
        best_params['n_jobs'] = -1
        
        if self.use_gpu:
            best_params['device'] = 'gpu'
            best_params['gpu_platform_id'] = 0
            best_params['gpu_device_id'] = 0
        
        logger.info(f"LightGBM optimization complete. Best accuracy: {study.best_value:.4f}")
        return best_params
    
    def prepare_time_series_data(self, X: np.ndarray, y: np.ndarray, 
                               sequence_length: int = 60) -> Tuple[np.ndarray, np.ndarray]:
        """Prepare data for LSTM time series modeling"""
        X_sequences = []
        y_sequences = []
        
        for i in range(sequence_length, len(X)):
            X_sequences.append(X[i-sequence_length:i])
            y_sequences.append(y[i])
        
        return np.array(X_sequences), np.array(y_sequences)
    
    def train_advanced_models(self, X_train: np.ndarray, y_train: np.ndarray,
                            X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, Any]:
        """Train advanced models targeting 99.8%+ accuracy"""
        logger.info(f"Training advanced models for 99.8%+ accuracy...")
        logger.info(f"Training data shape: {X_train.shape}, Validation data shape: {X_val.shape}")
        
        models = {}
        
        try:
            # 1. XGBoost with hyperparameter optimization
            if XGB_AVAILABLE and xgb is not None:
                logger.info("Training XGBoost model...")
                xgb_params = self.optimize_xgboost_hyperparameters(X_train, y_train, X_val, y_val, n_trials=30)
                xgb_model = xgb.XGBClassifier(**xgb_params)
                xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, early_stopping_rounds=20)
                models['xgboost'] = xgb_model
                
                # XGBoost predictions and metrics
                xgb_pred = xgb_model.predict(X_val)
                xgb_pred_safe = safe_array_conversion(xgb_pred)
                xgb_accuracy = accuracy_score(y_val, xgb_pred_safe)
                xgb_f1 = f1_score(y_val, xgb_pred_safe, average='weighted')
                xgb_precision = precision_score(y_val, xgb_pred_safe, average='weighted', zero_division=0)
                
                logger.info(f"XGBoost - Accuracy: {xgb_accuracy:.4f}, F1: {xgb_f1:.4f}, Precision: {xgb_precision:.4f}")
            else:
                logger.warning("XGBoost not available - skipping XGBoost training")
            
        except Exception as e:
            logger.error(f"XGBoost training failed: {str(e)}")
        
        try:
            # 2. LightGBM with hyperparameter optimization
            if LGB_AVAILABLE and lgb is not None:
                logger.info("Training LightGBM model...")
                lgb_params = self.optimize_lightgbm_hyperparameters(X_train, y_train, X_val, y_val, n_trials=30)
                lgb_model = lgb.LGBMClassifier(**lgb_params)  # type: ignore[attr-defined]
                lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(20), lgb.log_evaluation(0)])  # type: ignore[attr-defined]
                models['lightgbm'] = lgb_model
                
                # LightGBM predictions and metrics
                lgb_pred = lgb_model.predict(X_val)
                lgb_pred_safe = safe_array_conversion(lgb_pred)
                lgb_accuracy = accuracy_score(y_val, lgb_pred_safe)
                lgb_f1 = f1_score(y_val, lgb_pred_safe, average='weighted')
                lgb_precision = precision_score(y_val, lgb_pred_safe, average='weighted', zero_division=0)
                
                logger.info(f"LightGBM - Accuracy: {lgb_accuracy:.4f}, F1: {lgb_f1:.4f}, Precision: {lgb_precision:.4f}")
            else:
                logger.warning("LightGBM not available - skipping LightGBM training")
            
        except Exception as e:
            logger.error(f"LightGBM training failed: {str(e)}")
        
        try:
            # 3. CatBoost
            if CATBOOST_AVAILABLE and CatBoostClassifier is not None:
                logger.info("Training CatBoost model...")
                catboost_params = {
                    'iterations': 1000,
                    'learning_rate': 0.1,
                    'depth': 8,
                    'l2_leaf_reg': 3,
                    'random_seed': 42,
                    'verbose': False,
                    'early_stopping_rounds': 20,
                    'eval_metric': 'Accuracy'
                }
                
                if self.use_gpu:
                    catboost_params['task_type'] = 'GPU'
                    catboost_params['gpu_id'] = 0
                
                cat_model = CatBoostClassifier(**catboost_params)
                cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)
                models['catboost'] = cat_model
                
                # CatBoost predictions and metrics
                cat_pred = cat_model.predict(X_val)
                cat_pred_safe = safe_array_conversion(cat_pred)
                cat_accuracy = accuracy_score(y_val, cat_pred_safe)
                cat_f1 = f1_score(y_val, cat_pred_safe, average='weighted')
                cat_precision = precision_score(y_val, cat_pred_safe, average='weighted', zero_division=0)
                
                logger.info(f"CatBoost - Accuracy: {cat_accuracy:.4f}, F1: {cat_f1:.4f}, Precision: {cat_precision:.4f}")
            else:
                logger.warning("CatBoost not available - skipping CatBoost training")
            
        except Exception as e:
            logger.error(f"CatBoost training failed: {str(e)}")
        
        try:
            # 4. LSTM Model
            if TF_AVAILABLE and tf is not None and len(X_train) > 100:  # Only train LSTM if we have sufficient data
                logger.info("Training LSTM model...")
                
                # Prepare time series data
                sequence_length = min(60, len(X_train) // 10)
                X_train_lstm, y_train_lstm = self.prepare_time_series_data(X_train, y_train, sequence_length)
                X_val_lstm, y_val_lstm = self.prepare_time_series_data(X_val, y_val, sequence_length)
                
                if len(X_train_lstm) > 0 and len(X_val_lstm) > 0:
                    # Create LSTM model
                    lstm_model = self.create_lstm_model(
                        input_shape=(sequence_length, X_train.shape[1]),
                        num_classes=2
                    )
                    
                    if lstm_model is not None:
                        # Simple training without callbacks if TensorFlow callbacks not available
                        callbacks = []
                        if TF_AVAILABLE and tf is not None:
                            try:
                                # Try to import and use TensorFlow callbacks
                                EarlyStopping = tf.keras.callbacks.EarlyStopping
                                ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau
                                early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)
                                reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)
                                callbacks = [early_stopping, reduce_lr]
                            except (ImportError, TypeError, AttributeError):
                                # Fallback to no callbacks
                                callbacks = []
                        
                        # Train LSTM
                        try:
                            history = lstm_model.fit(
                                X_train_lstm, y_train_lstm,
                                validation_data=(X_val_lstm, y_val_lstm),
                                epochs=50,  # Reduced epochs for safety
                                batch_size=32,
                                callbacks=callbacks,
                                verbose=0
                            )
                        except Exception as fit_error:
                            logger.warning(f"LSTM training with callbacks failed: {fit_error}, trying simple training")
                            # Fallback to simple training
                            history = lstm_model.fit(
                                X_train_lstm, y_train_lstm,
                                validation_data=(X_val_lstm, y_val_lstm),
                                epochs=20,
                                batch_size=32,
                                verbose=0
                            )
                        
                        models['lstm'] = lstm_model
                        
                        # LSTM predictions and metrics
                        
                        models['lstm'] = lstm_model
                        
                        # LSTM predictions and metrics
                        lstm_pred_proba = lstm_model.predict(X_val_lstm)
                        lstm_pred = (lstm_pred_proba > 0.5).astype(int).flatten()
                        lstm_pred_safe = safe_array_conversion(lstm_pred)
                        lstm_accuracy = accuracy_score(y_val_lstm, lstm_pred_safe)
                        lstm_f1 = f1_score(y_val_lstm, lstm_pred_safe, average='weighted')
                        lstm_precision = precision_score(y_val_lstm, lstm_pred_safe, average='weighted', zero_division=0)
                        
                        logger.info(f"LSTM - Accuracy: {lstm_accuracy:.4f}, F1: {lstm_f1:.4f}, Precision: {lstm_precision:.4f}")
            else:
                logger.warning("TensorFlow not available or insufficient data - skipping LSTM training")
                    
        except Exception as e:
            logger.error(f"LSTM training failed: {str(e)}")
        
        # Store models and return
        self.models = models
        logger.info(f"Successfully trained {len(models)} advanced models")
        
        return models
    
    def create_ensemble_model(self, X_train: np.ndarray, y_train: np.ndarray) -> Any:
        """Create advanced ensemble model combining all trained models"""
        if not self.models:
            logger.error("No trained models available for ensemble")
            return None
        
        try:
            logger.info("Creating advanced ensemble model...")
            
            # Select best models for ensemble (exclude LSTM for VotingClassifier compatibility)
            ensemble_models = []
            model_names = []
            
            for name, model in self.models.items():
                if name != 'lstm':  # Exclude LSTM from sklearn ensemble
                    ensemble_models.append((name, model))
                    model_names.append(name)
            
            if len(ensemble_models) < 2:
                logger.warning("Insufficient models for ensemble. Using best single model.")
                return list(self.models.values())[0]
            
            # Create voting ensemble
            voting_ensemble = VotingClassifier(
                estimators=ensemble_models,
                voting='soft',  # Use probability voting for better performance
                n_jobs=-1
            )
            
            # Fit ensemble
            voting_ensemble.fit(X_train, y_train)
            
            logger.info(f"Ensemble model created with {len(ensemble_models)} models: {model_names}")
            return voting_ensemble
            
        except Exception as e:
            logger.error(f"Ensemble creation failed: {str(e)}")
            # Return best individual model as fallback
            return list(self.models.values())[0] if self.models else None
    
    def evaluate_comprehensive_metrics(self, model: Any, X_test: np.ndarray, y_test: np.ndarray, 
                                     model_name: str = "Model") -> Dict[str, float]:
        """Evaluate comprehensive metrics targeting 99.8%+ performance"""
        try:
            # Make predictions
            if hasattr(model, 'predict_proba'):
                y_pred_proba = model.predict_proba(X_test)
                y_pred = np.argmax(y_pred_proba, axis=1) if y_pred_proba.shape[1] > 1 else (y_pred_proba[:, 1] > 0.5).astype(int)
            else:
                y_pred = model.predict(X_test)
                # Ensure we have the right shape and type
                if hasattr(y_pred, 'shape') and len(y_pred.shape) > 1 and y_pred.shape[1] == 1:
                    y_pred = (y_pred > 0.5).astype(int).flatten()
                elif not hasattr(y_pred, 'shape'):
                    y_pred = np.array(y_pred)
                y_pred = np.array(y_pred).flatten()  # Ensure 1D array
            
            # Calculate comprehensive metrics
            y_pred_safe = safe_array_conversion(y_pred)
            accuracy = accuracy_score(y_test, y_pred_safe)
            precision = precision_score(y_test, y_pred_safe, average='weighted', zero_division=0)
            recall = recall_score(y_test, y_pred_safe, average='weighted', zero_division=0)
            f1 = f1_score(y_test, y_pred_safe, average='weighted', zero_division=0)
            
            # Calculate per-class metrics
            precision_macro = precision_score(y_test, y_pred_safe, average='macro', zero_division=0)
            recall_macro = recall_score(y_test, y_pred_safe, average='macro', zero_division=0)
            f1_macro = f1_score(y_test, y_pred_safe, average='macro', zero_division=0)
            
            metrics = {
                'accuracy': accuracy,
                'precision_weighted': precision,
                'recall_weighted': recall,
                'f1_weighted': f1,
                'precision_macro': precision_macro,
                'recall_macro': recall_macro,
                'f1_macro': f1_macro
            }
            
            logger.info(f"{model_name} Performance Metrics:")
            logger.info(f"  Accuracy: {accuracy:.6f}")
            logger.info(f"  Precision (weighted): {precision:.6f}")
            logger.info(f"  Recall (weighted): {recall:.6f}")
            logger.info(f"  F1-Score (weighted): {f1:.6f}")
            logger.info(f"  F1-Score (macro): {f1_macro:.6f}")
            
            # Check if target accuracy is achieved
            if accuracy >= self.target_accuracy:
                logger.info(f"ðŸŽ¯ TARGET ACHIEVED! {model_name} accuracy: {accuracy:.6f} >= {self.target_accuracy:.6f}")
            else:
                remaining = self.target_accuracy - accuracy
                logger.info(f"Target gap: {remaining:.6f} ({remaining*100:.4f}% points remaining)")
            
            return metrics
            
        except Exception as e:
            logger.error(f"Error evaluating {model_name}: {str(e)}")
            return {
                'accuracy': 0.0,
                'precision_weighted': 0.0,
                'recall_weighted': 0.0,
                'f1_weighted': 0.0,
                'precision_macro': 0.0,
                'recall_macro': 0.0,
                'f1_macro': 0.0
            }
    
    def train_and_evaluate(self, X_train: np.ndarray, y_train: np.ndarray,
                          X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:
        """Complete training and evaluation pipeline for 99.8%+ accuracy"""
        logger.info("Starting comprehensive training and evaluation...")
        
        # Split training data for validation
        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
            X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
        )
        
        # Train advanced models
        trained_models = self.train_advanced_models(X_train_split, y_train_split, X_val_split, y_val_split)
        
        if not trained_models:
            logger.error("No models were successfully trained!")
            return {'best_accuracy': 0.0, 'best_model': None}
        
        # Create ensemble
        ensemble_model = self.create_ensemble_model(X_train, y_train)
        if ensemble_model is not None:
            trained_models['ensemble'] = ensemble_model
        
        # Evaluate all models on test set
        results = {}
        best_accuracy = 0.0
        best_model = None
        best_model_name = None
        
        for name, model in trained_models.items():
            metrics = self.evaluate_comprehensive_metrics(model, X_test, y_test, name.upper())
            results[name] = {
                'model': model,
                'metrics': metrics
            }
            
            # Track best model
            if metrics['accuracy'] > best_accuracy:
                best_accuracy = metrics['accuracy']
                best_model = model
                best_model_name = name
        
        # Store results
        self.performance_metrics = results
        
        # Summary
        logger.info("\n" + "="*80)
        logger.info("ADVANCED TREND PREDICTION RESULTS")
        logger.info("="*80)
        logger.info(f"Target Accuracy: {self.target_accuracy:.6f} ({self.target_accuracy*100:.4f}%)")
        logger.info(f"Best Model: {best_model_name.upper() if best_model_name else 'UNKNOWN'}")
        logger.info(f"Best Accuracy: {best_accuracy:.6f} ({best_accuracy*100:.4f}%)")
        
        if best_accuracy >= self.target_accuracy:
            logger.info("ðŸŽ¯ TARGET ACHIEVED! 99.8%+ accuracy reached!")
        else:
            gap = self.target_accuracy - best_accuracy
            logger.info(f"Gap to target: {gap:.6f} ({gap*100:.4f}% points)")
        
        logger.info("="*80)
        
        return {
            'best_accuracy': best_accuracy,
            'best_model': best_model,
            'best_model_name': best_model_name,
            'all_results': results,
            'target_achieved': best_accuracy >= self.target_accuracy
        }

def main():
    """Test the advanced trend prediction system"""
    # Create sample data for testing
    np.random.seed(42)
    n_samples = 1000
    n_features = 50
    
    X_train = np.random.randn(n_samples, n_features)
    y_train = np.random.randint(0, 2, n_samples)
    X_test = np.random.randn(200, n_features)
    y_test = np.random.randint(0, 2, 200)
    
    # Initialize predictor
    predictor = AdvancedTrendPredictor(target_accuracy=0.998)
    
    # Train and evaluate
    results = predictor.train_and_evaluate(X_train, y_train, X_test, y_test)
    
    print(f"Best model achieved: {results['best_accuracy']:.6f} accuracy")

if __name__ == "__main__":
    main()